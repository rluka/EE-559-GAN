{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyNt275r0wv7"
   },
   "source": [
    "#Marked exercises after Lecture 10 on GANs\n",
    "\n",
    "This notebook contains the marked exercises with instructions and explanations.\n",
    "\n",
    "Work through the cells below in sequential order, executing each cell as you progress. Throughout the exercise, you will encounter instructions marked with the words **YOUR CODE HERE** followed by **raise NotImplementedError()**. You will have to substitute  *raise NotImplementedError()* with your own code.\n",
    "Follow the instructions and write the code to complete the tasks.\n",
    "\n",
    "Along the way, you may also find questions. Try to reflect on the questions before/after running the code.\n",
    "\n",
    "This notebook was developed at the [Idiap Research Institute](https://www.idiap.ch) by [Alina Elena Baia](mailto:alina.baia.idiap.ch>), [Darya Baranouskaya](mailto:darya.baranouskaya.idiap.ch) and [Olena Hrynenko](mailto:olena.hrynenko.idiap.ch) (equal contribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKvAudPzlqc8"
   },
   "source": [
    "Note: This notebook serves as the main file for the marked exercise and contains  the  code for initialising the models, initialising the dataset, setting the hyperparameters for training, and training the model. No code implementation is required in this notebook file. You are allowed to change hyperparameters.\n",
    "\n",
    "Make sure to upload the required source files. You will be asked to modified these files in order to complete the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You are asked to complete the following tasks related to completing the implementation of a GAN model and its training function, training\n",
    "WGAN [40 points]\n",
    " - 2.10.1 [3 points] Implement DiscriminatorBlock in model.py.\n",
    " - 2.10.2 [5 points] Implement GeneratorBlock in model.py.\n",
    " - 2.10.3 [5 points] Compete Generator in model.py: specify kernel_sizes, stride_sizes, padding_sizes in Generator def __init__.\n",
    " - 2.10.4 [3 points] Implement weight clamping in trainer.py: def clamp_weights(self)\n",
    " - 2.10.5 [9 points] Implement Discriminator update step in trainer.py: def disc_step(self, z, real_images).\n",
    " - 2.10.6 [9 points] Implement Generator update step in trainer.py: def gen_step(self).\n",
    " - 2.10.7 [6 points] Complete the call of disc_step() and gen_step in train_epoch(). Train the GAN for at least 5000 iterations and 5 epochs, and report the generated images.\n",
    "\n",
    "Further instructions and explanations are provided in the accompanying README.md and files.\n",
    "\n",
    "**IMPORTANT REMINDER**: Make sure to also complete the following tasks, which do no require code implementation. Follow the instructions provided in the Marked_exercises_submission2_lecture10.pdf file.\n",
    "\n",
    "\n",
    "Questions [20 points] â€“ Make sure to reference any sources used\n",
    " - 2.10.8 [10 points] Challenges with training GANs (200 words max)\n",
    "Discuss mode collapse as a challenge with training GANs and choose a second challenge yourself. Outline methods that address these challenges. Additionally, state the cause for these challenges. Support your claims with formulas, plots, and graphs. One plot = 50 words.\n",
    "\n",
    " - 2.10.9 [10 points] Evaluation metrics for GANs (200 words max)\n",
    "Discuss two metrics for evaluating the performance of GANs. Describe the advantages and disadvantages of each metric. Support your claims with formulas, plots, and graphs. One plot = 50 words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from model import Generator, Discriminator, weights_init\n",
    "from trainer import WGANTrainer\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_fashion_mnist_dataset(batch_size):\n",
    "    transforms_fashion_mnist = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ])\n",
    "    dataset = datasets.FashionMNIST(root='./data', train=True, download=True,\n",
    "                                     transform=transforms_fashion_mnist)\n",
    "    # For testing your implementation we recommend to use a subset of the dataset to save images more often,\n",
    "    # although that would be reflected in the quality of the generated images\n",
    "    from torch.utils.data import Subset\n",
    "    dataset = Subset(dataset, range(40000))\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set the hyperparameters and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# You are allowed to change hyperparameters\n",
    "# Although, if you implemented everything correctly this hyperparmeters should work\n",
    "lr_gen = 0.00007\n",
    "lr_disc = 0.00005\n",
    "batch_size = 64\n",
    "weight_cliping_limit = 0.01\n",
    "n_critic_steps = 2\n",
    "n_image_channels = 1  #3 if RGB and 1 if Greyscale\n",
    "\n",
    "gen = Generator(in_channels=100, out_channels=n_image_channels)\n",
    "disc = Discriminator(in_channels=n_image_channels)\n",
    "\n",
    "print(gen.apply(weights_init))\n",
    "print(disc.apply(weights_init))\n",
    "\n",
    "gen.to(device)\n",
    "disc.to(device)\n",
    "\n",
    "# assert for you to check the correctness of the sizes of models outputs\n",
    "z = torch.rand((4, 100, 1, 1), device=device)\n",
    "fake_image = gen(z)\n",
    "assert list(fake_image.shape) == [4, n_image_channels, 32, 32]\n",
    "assert list(disc(fake_image).shape) == [4, 1, 1, 1]\n",
    "\n",
    "\n",
    "# WGAN with gradient clipping uses RMSprop instead of ADAM\n",
    "optimizer_gen = torch.optim.RMSprop(gen.parameters(), lr=lr_gen)\n",
    "optimizer_disc = torch.optim.RMSprop(disc.parameters(), lr=lr_disc)\n",
    "\n",
    "train_loader = load_fashion_mnist_dataset(batch_size)\n",
    "\n",
    "#initialise the trainer\n",
    "trainer = WGANTrainer(model_gen=gen, model_disc=disc,\n",
    "                        optimizer_gen=optimizer_gen, optimizer_disc=optimizer_disc,\n",
    "                        n_disc_steps=n_critic_steps, weight_cliping=weight_cliping_limit, device=device)\n",
    "\n",
    "#train WGAN\n",
    "trainer.train(n_epoches=30, train_loader=train_loader)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
